# -*- coding: utf-8 -*-
"""Medicine Recommedation System.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Ou5PKs6uHDcvE_fY3Vu-CU4xqtiSFohU

# Import Library
"""

import pandas as pd
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.metrics import precision_score, recall_score

import matplotlib.pyplot as plt
import seaborn as sns

import kagglehub

"""# Load Dataset"""

path = kagglehub.dataset_download("joymarhew/medical-reccomadation-dataset")

"""Download dataset from Kaggle and get the path."""

data = pd.read_csv(f"{path}/medical data.csv")
data.head(10)

"""Load the dataset and show the 10 first data.

# Exploratory Data Analysis
"""

data.info()

"""Show information about the data like the column names, non null count, and data type."""

data.isnull().sum()

"""Show num of null data of each column"""

data[data.isnull().any(axis=1)]

"""There are some null data. After check it rows as row, the data could not be used or normalized so the data will dropped"""

data = data.dropna()
data.shape

"""Dropped the null data and show the data shape."""

data.duplicated().sum()

"""There are 84 duplicated data"""

data[data.duplicated(subset=['Name', 'DateOfBirth'])].sort_values(by=['Name', 'DateOfBirth'])

"""I think it's okay to keep it because it's possible to someone have some diagnosis

## Fix the broken data

There are some broken data, in this case uncompleted words like "Femal", "e Anxiety, Palpitations", "h COVID-19 Exposure", "ation, Rest".
"""

def starts_with_lowercase(row):
    for value in row:
        if isinstance(value, str) and value and value[0].islower():
            return True
    return False

lowercase_rows = data[data.apply(starts_with_lowercase, axis=1)]
lowercase_rows

"""The row that cointais the broken data has the pattern that one of the column started with lower case, so we collect all of its and display the data."""

data['Symptoms'] = data['Symptoms'].str.replace(r'^e\s+', '', regex=True)

"""Remove the Symptoms columns that start with "e " because it trimmed from female (female -> femal)"""

replace_dict = {
    "Femal": "Female",
    "Femalee": "Female",
    "Femaleee": "Female",
    "Abdominal Pain, Bloating O": "Abdominal Pain, Bloating",
    "vereating" : "Overeating",
    "Rheumatoid Arthriti": "Rheumatoid Arthritis",
    "s Arthritis": "Arthritis",
    "Cough, Shortness of breat": "Cough, Shortness of breath",
    "h COVID-19 Exposure": "COVID-19 Exposure",
    "Allergic Reacti": "Allergic Reaction",
    "on Antihistamine": "Antihistamine",
    "Rheumatoid Arthrit": "Rheumatoid Arthritis",
    "is Arthritis": "Arthritis",
    "th COVID-19 Exposure": "COVID-19 Exposure",
    "Respiratory AntiInfection": "Respiratory",
    "virals, Rest": "Anti Infectionvirals, Rest",
    "Heat Exhaustion Hydr": "Heat Exhaustion",
    "ation, Rest": "Hydration, Rest",
    "Tension Headache Rel": "Tension Headache",
    "axation, NSAIDs": "Relaxation, NSAIDs",
    "Indigestion Anta": "Indigestion",
    "cids": "Antacids",
    "Menstrual Cramps Pai": "Menstrual Cramps",
    "n Relievers": "Pain Relievers",
    "Allergic Reaction An": "Allergic Reaction",
    "tihistamine": "Antihistamine",
    "Cough, Shortness of brea": "Cough, Shortness of breath",
    "tCOVID-19 Exposure": "COVID-19 Exposure",
    "iArthritis": "Arthritis	"
}

data.replace(replace_dict, inplace=True)

"""Make replace dictionary to fix the broken data then replace it to the dataframe."""

# recheck the data
lowercase_rows = data[data.apply(starts_with_lowercase, axis=1)]
lowercase_rows.shape

"""Okay, the data already fixed

## Univariate EDA
"""

data['DateOfBirth'] = pd.to_datetime(data['DateOfBirth'])

"""Changes the datatype of DateOfBrith ti datetime"""

plt.figure(figsize=(10, 6))
plt.hist(data['DateOfBirth'].dt.year, bins=20, color='skyblue', edgecolor='black')
plt.xlabel('Year of Birth')
plt.ylabel('Number of Patients')
plt.title('Distribution of Patient Birth Years')
plt.grid(axis='y', alpha=0.75)
plt.show()

"""The data distribution of Year of Birth start from 1972 to 2005. Because the data collect in 2023, we know that all of patient are an adult (17+)"""

data['Gender'].value_counts().plot(kind='bar', color='skyblue')
plt.xlabel('Gender')
plt.ylabel('Number of Patients')
plt.title('Distribution of Patient Gender')
plt

"""The distribution of gender relatively same for male and famale"""

fig, axes = plt.subplots(2, 2, figsize=(15, 10))
fig.suptitle("Top 10 Symptoms, Causes, Diseases, and Medicines", fontsize=16)
features = ['Symptoms', 'Causes', 'Disease', 'Medicine']

for i, feature in enumerate(features):
  row = i // 2
  col = i % 2

  value_counts = data[feature].value_counts().nlargest(10)
  axes[row, col].bar(value_counts.index, value_counts.values, color='skyblue')
  axes[row, col].set_title(f'Top 10 {feature}')
  axes[row, col].set_xlabel(feature)
  axes[row, col].set_ylabel('Frequency')
  axes[row, col].tick_params(axis='x', rotation=45, labelsize=8)
plt.tight_layout(rect=[0, 0.03, 1, 0.95])
plt.show()

"""Display the top 10 of each column. We can know that some symptoms, causes, disease and madicine show more than 10 times.

# Data Preprocessing
"""

data['Gender'] = data['Gender'].str.lower()
data['Symptoms'] = data['Symptoms'].str.lower()
data['Causes'] = data['Causes'].str.lower()
data['Disease'] = data['Disease'].str.lower()
data['Medicine'] = data['Medicine'].str.lower()

"""Convert the data to lower case to make the model learn easyly"""

data['combined_features'] = data['Symptoms'] + ' ' + data['Causes'] + ' ' + data['Disease']
data['combined_features'] = data['combined_features'].apply(lambda x:x.replace(',',' '))

"""We combine the features so that we can used to the next procces when make the TF-IDF later. We also removed the unused character like comma."""

data

"""## TF-IDF Vectorizer"""

tfidf = TfidfVectorizer(stop_words='english')
tfidf_matrix = tfidf.fit_transform(data['combined_features'])

"""Make the TF-IDF matrix to represent the features as a numeric vector. Every word is given weight by term frequency and inverse document frequency

# Content based filtering
"""

def create_medicine_recommender(data=data, tfidf_matrix=tfidf_matrix):
    try:
        medicine_similarity = cosine_similarity(tfidf_matrix, tfidf_matrix)

        medicine_similarity_df = pd.DataFrame(
            medicine_similarity,
            index=data['Medicine'],
            columns=data['Medicine']
        )

        return medicine_similarity_df

    except Exception as e:
        print(f"Error when try to create medicine recommender: {str(e)}")
        return None, None

"""create a medicine recommender system using cosine similarity based on the TF-IDF matrix of the combined features (symptoms, causes, and disease) of the medical data. This function return medicine similarity as dataframe to used to the next step when match the madicine"""

def get_medicine_recommendations(medicine_name, similarity_df, n_recommendations=3):
    try:
        similarity_df = similarity_df.reset_index().set_index('Medicine')

        if medicine_name not in similarity_df.index:
            return f"Medicine '{medicine_name}' not found in database"

        similar_scores = similarity_df[similarity_df.index == medicine_name]
        similar_scores = similar_scores.iloc[0]

        similar_medicines = similar_scores.sort_values(ascending=False)

        similar_medicines = similar_medicines.drop_duplicates().head(n_recommendations)

        return similar_medicines

    except Exception as e:
        return f"Error when try to get recommendation: {str(e)}"

"""in this function we get the madicine recommedation based on the similarity of the madicine that we input with the other madicine by the similarity df that we build from previous function. It's return top-n recommedation that is 3 by default"""

def get_recommendations_by_symptoms(symptoms, df=data):

    similarity_df = create_medicine_recommender()

    matching_rows = df[df['Symptoms'].str.contains(symptoms, case=False)]

    if matching_rows.empty:
        return "No matching symptoms found"

    reference_medicine = matching_rows.iloc[0]['Medicine']

    try:
        recommendations = get_medicine_recommendations(reference_medicine, similarity_df)
        return recommendations
    except KeyError:
        return f"Medicine '{reference_medicine}' not found in the similarity matrix."

"""this function is used to get the medicine by the symptoms. First, we find the madicine that have used for this symptom. After that we use madicine recommedation funtion berfore to get the madicine recommedation based on the madicine reference."""

recommendations = get_recommendations_by_symptoms('fatigue')
print(recommendations)

"""The code run seccesfully and can shoe the top 3 recommendation.

# Evaluation
"""

def evaluate_recommendation_system(test_data, similarity_df, k=3):
    recall_scores = []
    reciprocal_ranks = []

    for _, row in test_data.iterrows():
        query_symptoms = row['Symptoms']
        true_medicine = row['Medicine']

        recommendations = get_recommendations_by_symptoms(query_symptoms, df=data)

        if isinstance(recommendations, pd.Series):
            recommended_medicines = recommendations.index[:k]
        else:
            continue

        # Recall@k
        recall = len(set(recommended_medicines) & {true_medicine}) / 1  # Since true_medicine is single
        recall_scores.append(recall)

        # Mean Reciprocal Rank
        if true_medicine in recommended_medicines:
            rank = list(recommended_medicines).index(true_medicine) + 1
            reciprocal_ranks.append(1 / rank)
        else:
            reciprocal_ranks.append(0)

    avg_recall = np.mean(recall_scores)
    mrr = np.mean(reciprocal_ranks)

    return {
        "Recall@k": avg_recall.round(2),
        "MRR": mrr.round(2)
    }

"""this function evaluates the performance of a medicine recommendation system using Recall@k and Mean Reciprocal Rank (MRR). It iterates through test data, gets recommendations for symptoms, and compares them to the true medicine. By calculating the average recall and reciprocal rank, it provides metrics to assess the accuracy and ranking quality of the recommendations."""

test_data = data.sample(15, random_state=28)
similarity_df = create_medicine_recommender()

results = evaluate_recommendation_system(test_data, similarity_df)
print("Evaluation Results:", results)

"""we make the test data by randomly take the sample af the data and evaluate using previuos function. As the result we get Evaluation Results:

**Recall@k: 0.87**

**MRR: 0.73**
"""